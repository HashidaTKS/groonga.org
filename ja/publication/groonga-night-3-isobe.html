---
layout: ja
title: mroongaを使った、高速な対訳検索＆ダウンロードシステムについて
---
<section id="groonga-night-3-isobe">
  <h2>発表の資料</h2>
  <p>発表時の資料はこちらになります。</p>
  <p><a href="presentation/groonga-night-3-isobe.pdf">mroongaを使った、高速な対訳検索＆ダウンロードシステムについて</a></p>
  <p>また、全文検索エンジンgroongaを囲む夕べ3が終了した後、発表者の磯部さんが発表内容のシステムで追試の実験を行い、結果をご送付いただきました。それをまとめたものを次のセクションに掲載しています。</p>
  <p>発表時の資料と合わせてご覧ください。</p>

  <h2>追試の情報</h2>
  <p>発表で話した同じ型のキューブPC（HDDはSATA3）の別マシンにて、HDD上に単一テーブルとしてmroongaのDBを構成しました。そのDBに対してSQLを1つ実行したところ、19672件取得するのに6m41.472sかかりました。発表で紹介したシステム（テーブルを8分割した場合）だと、１秒ちょっとです。 </p>
  <p>この時実行したSQLの概要は次のようになっています。</p>
  <ul>
    <li>英語、又は日本語の「単語又はフレーズ一致」でありその英語欄と日本語欄にはmroongaのインデックスが張ってある</li>
    <li>その他のフィールドはselectの出力には含まれるが、where句では指定していない</li>
    <li>「blue」というありふれた単語で検索したので大量にヒットした</li>
  </ul>

  <p>このSQLの実行途中に、仮想メモリの状況を調べるために次のコマンドを実行しました。</p>
  <pre>$ vmstat 5 -S m</pre>

  <p>これは、5秒間隔でサンプリングし、単位はMBで表示することを示しています。このコマンドの結果は下記のようになりました。<p>
    <pre>
procs -----------memory---------- ---swap-- -----io---- --system--
-----cpu-----
r b swpd free buff cache si so bi bo in cs us sy id wa st
0 1 0 234 4 29272 0 0 6 39 0 1 2 1 97 0 0
0 1 0 238 2 29263 0 0 16930 0 260 583 0 0 87 12 0
0 1 0 237 2 29263 0 0 15630 0 218 521 0 0 87 12 0
0 1 0 227 2 29274 0 0 14932 0 199 488 0 0 87 12 0
0 1 0 230 2 29272 0 0 15733 0 223 526 0 0 87 12 0
0 1 0 230 2 29273 0 0 16881 0 224 547 0 0 88 12 0
1 0 0 229 2 29274 0 0 17005 1 244 541 0 0 88 12 0
0 1 0 223 2 29286 0 0 15174 0 215 507 0 0 88 12 0
0 1 0 225 2 29284 0 0 14918 0 201 490 0 0 87 12 0
0 1 0 236 2 29274 0 0 14257 0 208 485 0 0 87 12 0
0 1 0 239 2 29272 0 0 16314 2 228 529 0 0 88 12 0
p0 1 0 235 2 29277 0 0 17025 0 232 567 0 0 88 12 0
    </pre>
  <p>「bi」（ディスクから読み込んだ量）の欄を見ると、物凄い勢いでDiskを読んでいることがわかります。今回のPCは8CPUですので、「wa」欄（I/O待ち）の12%は、１CPU分フルに発生している状況です。</p>
  <p>この時のメモリの状況です。</p>
  <pre>
$ free -m
total used free shared buffers cached
Mem: 32110 30820 1289 0 2 27841
-/+ buffers/cache: 2977 29132
Swap: 1998 0 1998
  </pre>

  <p>Swapは全く発生していません。よって、Swapは関係なく、単純にディスクの読み込みで遅いことがわかります。</p>
  <p>つまり、BI的に、一括で大量のデータを取得する場合には、プレゼンのように、データをRAM-Disk上に置くのが有効である事が判ります。第1システムでのSWAPがある状況だと遅いと言う推測は外れでした。</p>
  <p>また、twitterでのつぶやきを見ると、5千万件以下の場合はテーブルのパーティショニングは必要ないかもしれない、ということなので、テーブルの分割は必要ないかもしれません。</p>
</section>
